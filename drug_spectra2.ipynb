{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <a href=http://www.datascience-paris-saclay.fr/>Paris Saclay Center for Data Science</a> </h1>\n",
    "\n",
    "<h2> RAMP on qualitative and quantitative non-invasive monitoring of anti-cancer drugs </h2>\n",
    "\n",
    "<i>Camille Marini (LTCI/CNRS), Alex Gramfort (LTCI/Télécom ParisTech), Sana Tfaili (Lip(Sys)²/UPSud), Laetitia Le (Lip(Sys)²/UPSud), Mehdi Cherti (LAL/CNRS), Balázs Kégl (LAL/CNRS)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Introduction </h2>\n",
    "\n",
    "<p>Chemotherapy is one of the most used treatment against cancer. It uses chemical substances (<a href=https://en.wikipedia.org/wiki/List_of_chemotherapeutic_agents>chemotherapeutic agents</a>) which kill cells that divide too quickly. These chemical substances are often diluted in a particular solution and packaged in bags, diffusers, or syringes, before being administered. <a href=https://books.google.fr/books?id=EB00rD8AqaYC&pg=PA188&lpg=PA188&dq=wrong+chemotherapeutic&source=bl&ots=m7EfyG6A3J&sig=ZVa0hLqDPFe2iExV6FOREJztN8c&hl=en&sa=X&ved=0ahUKEwj_5ZinkarMAhUFnBoKHaJiAgAQ6AEIKDAC#v=onepage&q=wrong%20chemotherapeutic&f=false>Wrong medication</a>  (wrong chemotherapeutic agent or wrong concentration) can have major impacts for patients. To prevent wrong medication, some recent French regulations impose the verification of anti-cancer drugs before their administration. The goal is to check that they contain the good chemotherapeutic agent with the good dosage. \n",
    "\n",
    "<p><a href=https://en.wikipedia.org/wiki/Raman_spectroscopy>Raman spectroscopy</a> could be used to make this check, since, theoretically, i) each molecule has a specific spectral fingerprint by which the molecule can be identified; and ii) the Raman intensity increases with the concentration of the molecule. The main advantage of spectroscopy above other methods (for example, liquid chromatography) is that it is non-destructive and non-invasive (measures are made without opening the drug containers). However, this method is rarely used in hospital environment because of the complexity of the spectral signals to analyze. Automating the analysis of these spectral signals could significantly help. Eventually, a complete analytical system (from measuring Raman spectra to identifying the chemotherapeutic agent and its concentration) could be designed, which would be easy to use and would prevent wrong medication. \n",
    "\n",
    "<p>In this context, the goal of this project is to develop prediction models able to <b>identify and quantify chemotherapeutic agents from their Raman spectra</b>.  \n",
    "\n",
    "<p>The Lip(Sys)² laboratory measured Raman spectra of 4 types of chemotherapeutic agents (called <i>molecule</i>) in 3 different packages (called <i>vial</i>), diluted in 9 different solutions (called <i>solute gammes</i>), and having different concentrations. A total of <b>360 spectra were measured for each agent</b>, except for one (348 spectra).<br>  \n",
    "\n",
    "Part of these data are saved in the file <code>train.csv</code> as follows (<code>n_samples</code> being the number of samples): \n",
    "<ul>\n",
    "    <li><b>molecule</b>: Type of chemotherapeutic agent. Six possible values: A for infliximab, B for bévacizumab, Q for ramucirumab, R for rituximab. Dimension: (<code>n_samples</code>,)</li>\n",
    "    <li><b>vial</b>: Vial type. Three possible values: 1, 2, 3. Dimension: (<code>1</code>, <code>n_samples</code>)</li>\n",
    "    <li><b>solute</b>: Solute group. Fourteen possible values: 1, 2, ..., 14. Dimension: (<code>1</code>, <code>n_samples</code>)</li>\n",
    "    <li><b>concentration</b>: Concentration of the molecule. Dimension: (<code>n_samples</code>, <code>1</code>)</li>\n",
    "    <li><b>spectra</b>: Intensity of Raman spectrum. Dimension: (<code>n_samples</code>, <code>1866</code>)</li>\n",
    "</ul>\n",
    "\n",
    "<p>To sum up, there are too objectives:\n",
    "\n",
    "<ul>\n",
    "    <li><b>classification</b>: predict which molecule it corresponds to given the spectrum.</li>\n",
    "    <li><b>regression</b>: predict the concentration of a molecule. The prediction should not depend on the vial or the solute group. The error metric is the mean absolute relative error (mare): $$\\frac{1}{n_{samples}}\\sum_{i=1}^{n_{samples}}\\left|\\frac{y_i-\\hat{y}_i}{y_i}\\right|$$ with $y$ and $\\hat{y}$ being the true and predicted concentration.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "* numpy>=1.10.0  \n",
    "* matplotlib>=1.5.0 \n",
    "* pandas>=0.17.0  \n",
    "* scikit-learn>=0.17 (different syntaxes for v0.17 and v0.18)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 5 columns):\n",
      "concentration    999 non-null int64\n",
      "molecule         999 non-null object\n",
      "solute           999 non-null int64\n",
      "spectra          999 non-null object\n",
      "vial             999 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 39.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#### Loading data\n",
    "data = pd.read_csv('train.csv')\n",
    "#### Variables in the data set and their type\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_df['spectra'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_df = data[['molecule', 'concentration']]\n",
    "X_df = data.drop(['molecule', 'concentration'], axis=1)\n",
    "spectra = X_df['spectra'].values                                        \n",
    "spectra = np.array([np.array(dd[1:-1].split(',')).astype(float) for dd in spectra])    \n",
    "X_df['spectra'] = spectra.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['spectra'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   solute                                            spectra  vial\n",
      "0      11  [0.0152963, 0.0152944, 0.0153142, 0.0154096, 0...     1\n",
      "1       1  [0.0143634, 0.0143292, 0.0143999, 0.0145162, 0...     1\n",
      "2       3  [0.0163027, 0.0161848, 0.0163573, 0.0164119, 0...     1\n",
      "3      10  [0.0135833, 0.0135537, 0.0134438, 0.0136424, 0...     2\n",
      "4       2  [0.020811, 0.020767, 0.0208674, 0.0207018, 0.0...     3\n",
      "  molecule  concentration\n",
      "0        Q           8000\n",
      "1        B            500\n",
      "2        B           2000\n",
      "3        A           2000\n",
      "4        B          10000\n"
     ]
    }
   ],
   "source": [
    "print(X_df.head())\n",
    "print(y_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "For your submissions, you have to write 4 classes, saved in 4 different files:   \n",
    "* the class <code>FeatureExtractorClf</code>, which will be used to extract features for classification from the dataset and produce a numpy array of size (number of samples, dim of features).  \n",
    "* a class <code>Classification</code> to predict the molecule type  \n",
    "* the class <code>FeatureExtractorReg</code>, which will be used to extract features for regression from the dataset and produce a numpy array of size (number of samples, dim of features).  \n",
    "* a class <code>Regression</code> to predict the molecule concentration  \n",
    "\n",
    "When submitting these files, they are uploaded to our servers and run to give you a score!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature extractor for classification is implemented by the function <code>transform</code> and is saved in the file <code>feature_extractor_clf.py</code>. It receives the pandas dataframe <code>X_df</code> defined at the beginning of the notebook. It should produce a numpy array representing the features extracted, which would be used for the classification.  \n",
    "\n",
    "Below is an example of a feature extractor. You can copy-paste it into your <code>feature_extractor_clf.py</code> file or write a new one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0152963, 0.0152944, 0.0153142, 0.0154096, 0...\n",
       "1    [0.0143634, 0.0143292, 0.0143999, 0.0145162, 0...\n",
       "2    [0.0163027, 0.0161848, 0.0163573, 0.0164119, 0...\n",
       "3    [0.0135833, 0.0135537, 0.0134438, 0.0136424, 0...\n",
       "4    [0.020811, 0.020767, 0.0208674, 0.0207018, 0.0...\n",
       "Name: spectra, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Décomposition Spectra en plusieurs variables\n",
    "X_df['spectra'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Centrer et réduire mes données\n",
    "XX = np.array([np.array(dd) for dd in X_df['spectra']])                  \n",
    "XX -= np.mean(XX, axis=1)[:, None]                                     \n",
    "XX /= np.sqrt(np.sum(XX ** 2, axis=1))[:, None]                          \n",
    "#XX = np.concatenate([XX, X_df[labels].values], axis=1)                   \n",
    "#return XX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pca=PCA()\n",
    "\n",
    "#--------------------------------------------\n",
    "# Plot the PCA spectrum\n",
    "#pca.fit(spectra)\n",
    "#pca.fit(XX)\n",
    "#print(pca.explained_variance_ratio_)\n",
    "#--------------------------------------------\n",
    "#print(pca.explained_variance_ratio_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x26500eafb38>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb8AAAFHCAYAAAAx0kIGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x265758e0c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(7, 5))\n",
    "#plt.clf()\n",
    "plt.axis([0, 10, 0., 1])\n",
    "plt.plot(pca.explained_variance_ratio_, linewidth=2)\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca1 = PCA(n_components=2)\n",
    "#X_pca = pca1.fit_transform(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.decomposition import KernelPCA\\npca2=KernelPCA(n_components=2)\\nX_pca2=pca2.fit_transform(spectra)\\nprint(X_pca.shape)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.decomposition import KernelPCA\n",
    "pca2=KernelPCA(n_components=2)\n",
    "X_pca2=pca2.fit_transform(spectra)\n",
    "print(X_pca.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class FeatureExtractorClf(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_df):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    #def transform(self, X_df):\n",
    "        #XX = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "        #return XX\n",
    "#### Centrer et réduire les données    \n",
    "    def transform(self, X_df):\n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "        return XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification: predicting the molecule type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier follows a classical scikit-learn classifier template. It should be saved in the file <code>classifier.py</code>. In its simplest form it takes a scikit-learn pipeline and assignes it to <code>self.clf</code> in <code>__init__</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PREMIER TEST AVEC PCA WITH 10 COMPONENTS AND RANDOMFORESTCLASSIFIER **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier,BaggingClassifier\n",
    "from sklearn.decomposition import PCA,KernelPCA,NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#'clf', GradientBoostingClassifier(n_estimators=self.n_estimators, random_state=42)\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.n_components = 11\n",
    "        self.n_estimators = 300\n",
    "        self.clf = Pipeline([\n",
    "            ('Pca',PCA(n_components=self.n_components)), \n",
    "            ('clf', LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=200, \n",
    "                                       fit_intercept=True, intercept_scaling=1, class_weight=None, \n",
    "                                       random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                                       verbose=0, warm_start=False, n_jobs=1))\n",
    "        ])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''from sklearn.cluster import SpectralClustering\n",
    "import scipy as sp\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "i=0\n",
    "n_neighbors_list=[10,20,30]\n",
    "for k in n_neighbors_list:\n",
    "    spectral = SpectralClustering(n_clusters=4\n",
    "                              ,eigen_solver='arpack'\n",
    "                              ,affinity=\"nearest_neighbors\"\n",
    "                              ,n_neighbors=k              \n",
    "                             )\n",
    "    spectral_clustering=spectral.fit_predict(spectra)\n",
    "    plt.figure(figsize=(15.0, 4.0))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Spectral prediction\"+ \" using knn graph k = \"+str(k), fontsize=16)\n",
    "    plt.scatter(x=X_pca[:,0],y=spectral_clustering,c=getColors(spectral_clustering))\n",
    "    \n",
    "    fig = pylab.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(X_pca[:,0],X_pca[:,1],spectral_clustering,c=getColors(spectral_clustering))\n",
    "    pyplot.show()\n",
    "    \n",
    "    i=i+1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class EnsembleClassifier(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "\n",
    "    def __init__(self, clfs, voting='hard', weights=None):\n",
    "\n",
    "        self.clfs = clfs\n",
    "        self.named_clfs = {key:value for key,value in _name_estimators(clfs)}\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output'\\\n",
    "                                      ' classification is not supported.')\n",
    "\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n",
    "                             % voting)\n",
    "\n",
    "        if self.weights and len(self.weights) != len(self.clfs):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d clfs'\n",
    "                             % (len(self.weights), len(self.clfs)))\n",
    "\n",
    "        self.le_ = LabelEncoder()\n",
    "        self.le_.fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.clfs_ = []\n",
    "        for clf in self.clfs:\n",
    "            fitted_clf = clone(clf).fit(X, self.le_.transform(y))\n",
    "            self.clfs_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "       \n",
    "        if self.voting == 'soft':\n",
    "\n",
    "            maj = np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "        else:  # 'hard' voting\n",
    "            predictions = self._predict(X)\n",
    "\n",
    "            maj = np.apply_along_axis(\n",
    "                                      lambda x:\n",
    "                                      np.argmax(np.bincount(x,\n",
    "                                                weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=predictions)\n",
    "\n",
    "        maj = self.le_.inverse_transform(maj)\n",
    "        return maj\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "       \n",
    "        avg = np.average(self._predict_probas(X), axis=0, weights=self.weights)\n",
    "        return avg\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        if self.voting == 'soft':\n",
    "            return self._predict_probas(X)\n",
    "        else:\n",
    "            return self._predict(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Return estimator parameter names for GridSearch support\"\"\"\n",
    "        if not deep:\n",
    "            return super(EnsembleClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_clfs.copy()\n",
    "            for name, step in six.iteritems(self.named_clfs):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\" Collect results from clf.predict calls. \"\"\"\n",
    "        return np.asarray([clf.predict(X) for clf in self.clfs_]).T\n",
    "\n",
    "    def _predict_probas(self, X):\n",
    "        \"\"\" Collect results from clf.predict calls. \"\"\"\n",
    "        return np.asarray([clf.predict_proba(X) for clf in self.clfs_])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "ada=AdaBoostClassifier(RandomForestClassifier( max_depth=5,class_weight=\"balanced\",n_estimators=10),n_estimators=10)\n",
    "gbc=GradientBoostingClassifier(max_depth=5,min_samples_split=4,learning_rate=0.3,max_features='log2',n_estimators=100,warm_start=True)\n",
    "svc=SVC(kernel =\"linear\",class_weight='balanced',shrinking=True,probability=True)\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pipe1 = Pipeline([\n",
    "            ('imputer', Imputer(strategy='most_frequent')),\n",
    "            ('eclf', EnsembleClassifier(clfs=[gbc,svc,ada],voting='hard'))\n",
    "            \n",
    "        ])\n",
    "        pipe2 = Pipeline([\n",
    "            ('imputer', Imputer(strategy='most_frequent')),\n",
    "            ('knn',KNeighborsClassifier(n_neighbors=5) )\n",
    "            \n",
    "        ])\n",
    "        \n",
    "        self.clf = EnsembleClassifier(clfs=[pipe1,pipe2],voting='soft',weights=[4,1])  \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the feature extractor and classifier together and see what we get.  \n",
    "**You will not have to submit the function <code>train_test_model_clf</code>.** A similar function is implemented on our servers. Your class and associated methods should be called the same way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.03\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A       0.97      0.97      0.97        63\n",
      "          B       0.98      0.91      0.94        45\n",
      "          Q       1.00      1.00      1.00        40\n",
      "          R       0.95      1.00      0.97        52\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "confusion matrix:\n",
      " [[61  1  0  1]\n",
      " [ 2 41  0  2]\n",
      " [ 0  0 40  0]\n",
      " [ 0  0  0 52]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "#from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "def train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Classifier):\n",
    "    train_is, test_is = skf_is\n",
    "    X_train_df = X_df.iloc[train_is].copy()                                  \n",
    "    y_train_df = y_df.iloc[train_is].copy()\n",
    "    y_train_clf = y_train_df['molecule'].values\n",
    "    X_test_df = X_df.iloc[test_is].copy()                                    \n",
    "    y_test_df = y_df.iloc[test_is].copy() \n",
    "    y_test_clf = y_test_df['molecule'].values \n",
    "    # Feature extraction\n",
    "    fe_clf = FeatureExtractor()\n",
    "    fe_clf.fit(X_train_df, y_train_df)\n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)\n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)\n",
    "    # Train\n",
    "    clf = Classifier()\n",
    "    clf.fit(X_train_array_clf, y_train_clf)\n",
    "    # Test \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]                      \n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = %s' % error)                                                                            \n",
    "    print('classification report:\\n %s' % classification_report(y_test_clf, y_pred_clf))\n",
    "    print('confusion matrix:\\n %s' % confusion_matrix(y_test_clf, y_pred_clf))\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57)  \n",
    "skf_is = list(skf.split(X_df))[0]\n",
    "\n",
    "train_test_model_clf(X_df, y_df, skf_is, FeatureExtractorClf, Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** DEUXIEME TEST AVEC PCA WITH 10 COMPONENTS AND LDA **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for regression\n",
    "\n",
    "Similarly to the feature extractor for classification, the feature extractor for regression should be implemented by a function <code>transform</code> and be part of the <code>FeatureExtractorReg</code> class, saved in the file <code>feature_extractor_reg.py</code>.  \n",
    "<code>transform</code> receives the pandas dataframe <code>X_df</code> defined at the beginning of the notebook. The dataframe is augmented by four columns. At train time these columns contain the one-hot encoded molecule type; at test time, it receives the class posteriors. In this way you can use the classification information in the feature extractor of the regressor. The feature extractor should produce a numpy array representing the features extracted, which would be used for the regression.\n",
    "\n",
    "In the example below, the features extracted are the molecule types and the standardized Raman spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "class FeatureExtractorReg(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df):                                                   \n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])                  \n",
    "        XX -= np.median(XX, axis=1)[:, None]                                     \n",
    "        XX /= np.sqrt(np.sum(XX ** 2, axis=1))[:, None]                          \n",
    "        XX = np.concatenate([XX, X_df[labels].values], axis=1)                   \n",
    "        return XX   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression: predicting the concentration\n",
    "\n",
    "The regressor follows a classical scikit-learn regressor template. It should be saved in the file <code>regressor.py</code>. In its simplest form it takes a scikit-learn pipeline and assignes it to <code>self.reg</code> in <code>__init__</code>.  \n",
    "\n",
    "In the example below, one model is created for each type of molecule\n",
    "\n",
    "As mentionned above, the error metric is the mean absolute relative error (mare): $$\\frac{1}{n_{samples}}\\sum_{k=1}^{n_{samples}}\\left|\\frac{y-\\hat{y}}{y}\\right|$$ with $y$ and $\\hat{y}$ being the true and predicted concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor                           \n",
    "from sklearn.decomposition import PCA ,KernelPCA                                           \n",
    "from sklearn.pipeline import Pipeline                                            \n",
    "from sklearn.base import BaseEstimator                                           \n",
    "import numpy as np     \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "                                                                                 \n",
    "                                                                                 \n",
    "class Regressor(BaseEstimator):                                                  \n",
    "    def __init__(self):                                                          \n",
    "        self.n_components = 10                                                  \n",
    "        self.n_estimators = 500                                                   \n",
    "        self.learning_rate = 0.20                                                 \n",
    "        self.list_molecule = ['A', 'B', 'Q', 'R']                                \n",
    "        self.dict_reg = {}                                                       \n",
    "        for mol in self.list_molecule:                                           \n",
    "            self.dict_reg[mol] = Pipeline([                                      \n",
    "                ('pca', PCA(n_components=self.n_components)),                    \n",
    "                ('reg', GradientBoostingRegressor(                               \n",
    "                    n_estimators=self.n_estimators,                              \n",
    "                    learning_rate=self.learning_rate,                            \n",
    "                    random_state=42))                                            \n",
    "            ])                                                                   \n",
    "                                                                                 \n",
    "    def fit(self, X, y):                                                         \n",
    "        for i, mol in enumerate(self.list_molecule):                             \n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]             \n",
    "            XX_mol = X[ind_mol]                                                  \n",
    "            y_mol = y[ind_mol].astype(float)                                     \n",
    "            self.dict_reg[mol].fit(XX_mol, np.log(y_mol))                        \n",
    "                                                                                 \n",
    "    def predict(self, X):                                                        \n",
    "        y_pred = np.zeros(X.shape[0])                                            \n",
    "        for i, mol in enumerate(self.list_molecule):                             \n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]             \n",
    "            XX_mol = X[ind_mol].astype(float)                                    \n",
    "            y_pred[ind_mol] = np.exp(self.dict_reg[mol].predict(XX_mol))         \n",
    "        return y_pred                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the feature extraction, classification, and regression together, and see what we get!  \n",
    "\n",
    "As mentionned above, **you will not have to submit the function <code>train_test_model</code>**. A similar function is implemented on our servers. Your class and associated methods should be called the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  0.025\n",
      "mare =  0.155318640586\n",
      "combined error =  0.0684395468618\n"
     ]
    }
   ],
   "source": [
    "def mare_score(y_true, y_pred):                                                  \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) \n",
    "\n",
    "def train_test_model(X_df, y_df, skf_is, FeatureExtractorClf, Classifier, FeatureExtractorReg, Regressor):\n",
    "    train_is, test_is = skf_is\n",
    "    X_train_df = X_df.iloc[train_is].copy()                                  \n",
    "    y_train_df = y_df.iloc[train_is].copy()                                  \n",
    "    X_test_df = X_df.iloc[test_is].copy()                                    \n",
    "    y_test_df = y_df.iloc[test_is].copy()                                    \n",
    "    y_train_clf = y_train_df['molecule'].values                              \n",
    "    y_train_reg = y_train_df['concentration'].values                         \n",
    "    y_test_clf = y_test_df['molecule'].values                                \n",
    "    y_test_reg = y_test_df['concentration'].values                           \n",
    "\n",
    "    # Classification\n",
    "    fe_clf = FeatureExtractorClf()                     \n",
    "    fe_clf.fit(X_train_df, y_train_df)                                       \n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)                         \n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)                           \n",
    "                                                                                 \n",
    "    clf = Classifier()                                            \n",
    "    clf.fit(X_train_array_clf, y_train_clf)                                  \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]                      \n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = ', error)\n",
    "    \n",
    "    # Regression\n",
    "    fe_reg = FeatureExtractorReg()                     \n",
    "    for i, label in enumerate(labels):\n",
    "        # For training, we use \n",
    "        X_train_df.loc[:, label] = (y_train_df['molecule'] == label)         \n",
    "        X_test_df.loc[:, label] = y_proba_clf[:, i]                          \n",
    "    fe_reg.fit(X_train_df, y_train_reg)                                      \n",
    "    X_train_array_reg = fe_reg.transform(X_train_df)                         \n",
    "    X_test_array_reg = fe_reg.transform(X_test_df)                           \n",
    "                                                                                 \n",
    "    reg = Regressor()                                              \n",
    "    reg.fit(X_train_array_reg, y_train_reg)                               \n",
    "    y_pred_reg = reg.predict(X_test_array_reg)\n",
    "    mare = mare_score(y_test_reg, y_pred_reg)\n",
    "    print('mare = ', mare)                \n",
    "    print('combined error = ', 2. / 3 * error + 1. / 3 * mare)\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57) \n",
    "skf_is = list(skf.split(X_df))[0]\n",
    "\n",
    "train_test_model(X_df, y_df, skf_is, FeatureExtractorClf, Classifier, FeatureExtractorReg, Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Unit testing\n",
    "\n",
    "You should use this notebook for preliminary analysis and visualization. Before submitting, you should make sure the code has no errors. First, copy-paste your four workflow elements into <code>feature_extractor_clf.py</code>, <code>feature_extractor_reg.py</code>, <code>classifier.py</code>, and <code>regressor.py</code>. Then execute the user_test_submission code, either in a separate terminal or below. You can also look at user_test_submission.py to see how we cross-validate and score your submissions. But don't modify it: its goal is to mimic what we do at our backend.\n",
    "\n",
    "**If it runs and prints**   \n",
    "<code>\n",
    "Reading file ...\n",
    "Training file ...\n",
    "<verb>--------------------------</verb>\n",
    "error =  [some_number_between_0_and_1]\n",
    "mare =  [some_number_between_0_and_1]\n",
    "combined error =  [some_number_between_0_and_1]\n",
    "<verb>--------------------------</verb>\n",
    "error =  [some_number_between_0_and_1]\n",
    "mare =  [some_number_between_0_and_1]\n",
    "combined error =  [some_number_between_0_and_1]\n",
    "</code>\n",
    "**you can submit the code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run user_test_submission.py and test your code from the notebook you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file ...\n",
      "Training file ...\n",
      "--------------------------\n",
      "error = 0.02\n",
      "mare =  0.0341904761905\n",
      "combined error =  0.0247301587302\n",
      "--------------------------\n",
      "error = 0.04\n",
      "mare =  0.0489781746032\n",
      "combined error =  0.0429927248677\n",
      "--------------------------\n",
      "error = 0.03\n",
      "mare =  0.0429642857143\n",
      "combined error =  0.0343214285714\n",
      "--------------------------\n",
      "error = 0.025\n",
      "mare =  0.0570238095238\n",
      "combined error =  0.0356746031746\n"
     ]
    }
   ],
   "source": [
    "!python user_test_submission.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
